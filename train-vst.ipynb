{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the parameters for the training\n",
    "\n",
    "Name = 'My Instrument' #@param {type:\"string\"}\n",
    "Name = Name.replace(' ', '_')\n",
    "\n",
    "Training_Steps = 30000\n",
    "\n",
    "Ignore_Previous = False\n",
    "\n",
    "Google_Drive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 14:26:51.452613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import IPython\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from ipyfilechooser import FileChooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_files(drive_dir, audio_dir):\n",
    "    if drive_dir:\n",
    "        # List all files in the drive_dir\n",
    "        all_files = os.listdir(drive_dir)\n",
    "        \n",
    "        # Filter out files that are not .mp3 or .wav\n",
    "        audio_paths = [f for f in all_files if f.endswith('.mp3') or f.endswith('.wav')]\n",
    "        audio_paths = [os.path.join(drive_dir, f) for f in audio_paths]  # Full paths\n",
    "        \n",
    "        if len(audio_paths) < 1:\n",
    "            raise FileNotFoundError(\"Sorry, it seems that there aren't any MP3 or \"\n",
    "                                    f\"WAV files in your folder ({drive_dir}). Try \"\n",
    "                                    \"running again and choose a different folder.\")\n",
    "    else:\n",
    "        # If no drive_dir is specified, handle as per your environment.\n",
    "        # This part might need to be modified based on where you're uploading files from.\n",
    "        print(\"Please specify a directory containing audio files.\")\n",
    "        return\n",
    "    \n",
    "    # Copy Audio.\n",
    "    print('Copying audio to local directory for training...')\n",
    "    for src in audio_paths:\n",
    "        target = os.path.join(audio_dir, \n",
    "                              os.path.basename(src).replace(' ', '_'))\n",
    "        print('Copying {} to {}'.format(src, target))\n",
    "        shutil.copy(src, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying audio to local directory for training...\n",
      "Copying samples/hls.mp3 to audio/hls.mp3\n"
     ]
    }
   ],
   "source": [
    "# test get_audio_files\n",
    "get_audio_files(\"samples/\",\"audio/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def directory_has_files(target_dir):\n",
    "    n_files = len([f for f in os.listdir(target_dir) if os.path.isfile(os.path.join(target_dir, f))])\n",
    "    return n_files > 0\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(audio_dir, \n",
    "                    data_dir,\n",
    "                    sample_rate=16000, \n",
    "                    frame_rate=50, \n",
    "                    example_secs=4.0, \n",
    "                    hop_secs=1.0, \n",
    "                    viterbi=True, \n",
    "                    center=True):\n",
    "  if directory_has_files(data_dir):\n",
    "    print(f'Dataset already exists in `{data_dir}`')\n",
    "    return\n",
    "  else:\n",
    "    # Otherwise prepare new dataset locally.\n",
    "    print(f'Preparing new dataset from `{audio_dir}`')\n",
    "\n",
    "    print()\n",
    "    print('Creating dataset...')\n",
    "    print('This usually takes around 2-3 minutes for each minute of audio')\n",
    "    print('(10 minutes of training audio -> 20-30 minutes)')\n",
    "\n",
    "    audio_filepattern = os.path.join(audio_dir, '*')\n",
    "    audio_fp_str = f'\"{audio_filepattern}\"'    \n",
    "    tfrecord_path_str = f'\"{data_dir}/train.tfrecord\"'\n",
    "\n",
    "    # print what we are going to run\n",
    "    print(\"Running the following command:\")\n",
    "    print(f\"!ddsp_prepare_tfrecord --input_audio_filepatterns={audio_fp_str} --output_tfrecord_path={tfrecord_path_str} --num_shards=10 --sample_rate={sample_rate} --frame_rate={frame_rate} --example_secs={example_secs} --hop_secs={hop_secs} --viterbi={viterbi} --center={center}\")\n",
    "\n",
    "    !ddsp_prepare_tfrecord \\\n",
    "    --input_audio_filepatterns=$audio_fp_str \\\n",
    "    --output_tfrecord_path=$tfrecord_path_str \\\n",
    "    --num_shards=10 \\\n",
    "    --sample_rate=$sample_rate \\\n",
    "    --frame_rate=$frame_rate \\\n",
    "    --example_secs=$example_secs \\\n",
    "    --hop_secs=$hop_secs \\\n",
    "    --viterbi=$viterbi \\\n",
    "    --center=$center &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test get_audio_files\n",
    "\n",
    "def get_model_dir(base_dir, ignore_previous=False):\n",
    "    base_str = 'ddsp-training'\n",
    "    # List all items in base_dir\n",
    "    all_items = os.listdir(base_dir)\n",
    "    \n",
    "    # Filter out directories that match the pattern\n",
    "    dirs = [item for item in all_items if os.path.isdir(os.path.join(base_dir, item)) and item.startswith(base_str)]\n",
    "    \n",
    "    # Sort the directories to find the most recent\n",
    "    dirs.sort()\n",
    "    \n",
    "    if dirs and not ignore_previous:\n",
    "        model_dir = os.path.join(base_dir, dirs[-1])  # Use the last directory as the most recent\n",
    "    else:\n",
    "        # If no suitable directory is found or if ignoring previous directories, create a new one.\n",
    "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
    "        model_dir = os.path.join(base_dir, f'{base_str}-{now}')\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)  # Create the directory since it does not exist\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "def reset_state(data_dir, audio_dir, model_dir):\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "        shutil.rmtree(audio_dir)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def export_and_download(model_dir, model_name=Name):\n",
    "  export_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "  model_dir_str=f'\"{model_dir}\"'\n",
    "  export_path_str=f'\"{export_path}\"'\n",
    "  \n",
    "  !ddsp_export \\\n",
    "  --name=$model_name \\\n",
    "  --model_path=$model_dir_str \\\n",
    "  --save_dir=$export_path_str \\\n",
    "  --inference_model=vst_stateless_predict_controls \\\n",
    "  --tflite \\\n",
    "  --notfjs\n",
    "\n",
    "  # Zip the whole directory.\n",
    "  zip_fname = f'{model_name}.zip'\n",
    "  zip_fp = os.path.join(model_dir, zip_fname)\n",
    "  print(f'Export complete! Zipping {export_path} to {zip_fp}')\n",
    "  print(f'Zipping Complete! Downloading... {zip_fname}')\n",
    "  print(f'You can also find your model at {export_path}')\n",
    "\n",
    "def train(model_dir, data_dir, steps=30000):\n",
    "  file_pattern = os.path.join(data_dir, 'train.tfrecord*')\n",
    "  fp_str = f\"TFRecordProvider.file_pattern='{file_pattern}'\"\n",
    "  !ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --save_dir=\"$model_dir\" \\\n",
    "  --gin_file=models/vst/vst.gin \\\n",
    "  --gin_file=datasets/tfrecord.gin \\\n",
    "  --gin_param=\"$fp_str\" \\\n",
    "  --gin_param=\"TFRecordProvider.centered=True\" \\\n",
    "  --gin_param=\"TFRecordProvider.frame_rate=50\" \\\n",
    "  --gin_param=\"batch_size=16\" \\\n",
    "  --gin_param=\"train_util.train.num_steps=$steps\" \\\n",
    "  --gin_param=\"train_util.train.steps_per_save=300\" \\\n",
    "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=3\"\n",
    "\n",
    "def get_gpu_type():\n",
    "    gpu_info = []\n",
    "    try:\n",
    "        bash_command = \"nvidia-smi --query-gpu=name --format=csv\"\n",
    "        output = subprocess.getoutput(bash_command)\n",
    "        lines = output.split(\"\\n\")\n",
    "        lines.pop(0)\n",
    "        return lines[0]\n",
    "    except OSError:\n",
    "        print(\"GPU device is not available\")\n",
    "        return ''\n",
    "\n",
    "\n",
    "# test get_audio_files\n",
    "\n",
    "def get_model_dir(base_dir, ignore_previous=False):\n",
    "    base_str = 'ddsp-training'\n",
    "    # List all items in base_dir\n",
    "    all_items = os.listdir(base_dir)\n",
    "    \n",
    "    # Filter out directories that match the pattern\n",
    "    dirs = [item for item in all_items if os.path.isdir(os.path.join(base_dir, item)) and item.startswith(base_str)]\n",
    "    \n",
    "    # Sort the directories to find the most recent\n",
    "    dirs.sort()\n",
    "    \n",
    "    if dirs and not ignore_previous:\n",
    "        model_dir = os.path.join(base_dir, dirs[-1])  # Use the last directory as the most recent\n",
    "    else:\n",
    "        # If no suitable directory is found or if ignoring previous directories, create a new one.\n",
    "        now = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
    "        model_dir = os.path.join(base_dir, f'{base_str}-{now}')\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)  # Create the directory since it does not exist\n",
    "    return model_dir\n",
    "\n",
    "\n",
    "def reset_state(data_dir, audio_dir, model_dir):\n",
    "    if os.path.exists(data_dir):\n",
    "        shutil.rmtree(data_dir)\n",
    "        shutil.rmtree(audio_dir)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def export_and_download(model_dir, model_name=Name):\n",
    "  export_path = os.path.join(model_dir, model_name)\n",
    "\n",
    "  model_dir_str=f'\"{model_dir}\"'\n",
    "  export_path_str=f'\"{export_path}\"'\n",
    "  \n",
    "  !ddsp_export \\\n",
    "  --name=$model_name \\\n",
    "  --model_path=$model_dir_str \\\n",
    "  --save_dir=$export_path_str \\\n",
    "  --inference_model=vst_stateless_predict_controls \\\n",
    "  --tflite \\\n",
    "  --notfjs\n",
    "\n",
    "  # Zip the whole directory.\n",
    "  zip_fname = f'{model_name}.zip'\n",
    "  zip_fp = os.path.join(model_dir, zip_fname)\n",
    "  print(f'Export complete! Zipping {export_path} to {zip_fp}')\n",
    "  print(f'Zipping Complete! Downloading... {zip_fname}')\n",
    "  print(f'You can also find your model at {export_path}')\n",
    "\n",
    "def train(model_dir, data_dir, steps=30000):\n",
    "  file_pattern = os.path.join(data_dir, 'train.tfrecord*')\n",
    "  print(file_pattern)\n",
    "  fp_str = f\"TFRecordProvider.file_pattern='{file_pattern}'\"\n",
    "  print(fp_str)\n",
    "  !ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --save_dir=\"$model_dir\" \\\n",
    "  --gin_file=models/vst/vst.gin \\\n",
    "  --gin_file=datasets/tfrecord.gin \\\n",
    "  --gin_param=\"$fp_str\" \\\n",
    "  --gin_param=\"TFRecordProvider.centered=True\" \\\n",
    "  --gin_param=\"TFRecordProvider.frame_rate=50\" \\\n",
    "  --gin_param=\"batch_size=16\" \\\n",
    "  --gin_param=\"train_util.train.num_steps=$steps\" \\\n",
    "  --gin_param=\"train_util.train.steps_per_save=300\" \\\n",
    "  --gin_param=\"trainers.Trainer.checkpoints_to_keep=3\"\n",
    "\n",
    "def get_gpu_type():\n",
    "    gpu_info = []\n",
    "    try:\n",
    "        bash_command = \"nvidia-smi --query-gpu=name --format=csv\"\n",
    "        output = subprocess.getoutput(bash_command)\n",
    "        lines = output.split(\"\\n\")\n",
    "        lines.pop(0)\n",
    "        return lines[0]\n",
    "    except OSError:\n",
    "        print(\"GPU device is not available\")\n",
    "        return ''\n",
    "\n",
    "def log_event(event_name, event_details):\n",
    "  \"\"\"Log event with name and details dictionary.\"\"\"\n",
    "  details_json = json.dumps(event_details)\n",
    "  js_string = \"gtag('event', '%s', %s);\" % (event_name, details_json)\n",
    "  IPython.display.display(IPython.display.Javascript(js_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(drive_dir=''):\n",
    "  log_event('runTrainingStarted', {})\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Install DDSP here to allow selecting folder first\n",
    "  # ------------------------------------------------------------------------------\n",
    "  print('Installing DDSP...')\n",
    "  print('This should take about 2 minutes...')\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Import DDSP\n",
    "  # ------------------------------------------------------------------------------\n",
    "  from ddsp.colab import colab_utils\n",
    "  globals()['colab_utils'] = colab_utils\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Setup\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Save data locally, but model on drive.\n",
    "  data_dir = 'data/'\n",
    "  audio_dir = 'audio/'\n",
    "  model_dir = get_model_dir(drive_dir)\n",
    "\n",
    "  reset_state(data_dir, audio_dir, model_dir)\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Dataset\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  get_audio_files(drive_dir, audio_dir)\n",
    "  prepare_dataset(audio_dir, data_dir)\n",
    "\n",
    "  log_event('datasetMins', {'value': round((time.time() - tick) // 60)})\n",
    "\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Train\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  print()\n",
    "  print('Training...')\n",
    "  train(model_dir, data_dir, steps=Training_Steps)\n",
    "\n",
    "  log_event('trainMins', {\n",
    "      'event_category': str(Training_Steps),\n",
    "      'value': round((time.time() - tick) // 60),\n",
    "  })\n",
    "\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Export\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  print()\n",
    "  print('Exporting model...')\n",
    "  export_and_download(model_dir)\n",
    "\n",
    "  log_event('exportMins', {'value': round((time.time() - tick) // 60)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gpu_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(drive_dir=''):\n",
    "  log_event('runTrainingStarted', {})\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Install DDSP here to allow selecting folder first\n",
    "  # ------------------------------------------------------------------------------\n",
    "  print('Installing DDSP...')\n",
    "  print('This should take about 2 minutes...')\n",
    "\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Setup\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Save data locally, but model on drive.\n",
    "  data_dir = 'data/'\n",
    "  audio_dir = 'audio/'\n",
    "  model_dir = get_model_dir(drive_dir)\n",
    "\n",
    "  reset_state(data_dir, audio_dir, model_dir)\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Dataset\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  get_audio_files(drive_dir, audio_dir)\n",
    "  prepare_dataset(audio_dir, data_dir)\n",
    "\n",
    "  log_event('datasetMins', {'value': round((time.time() - tick) // 60)})\n",
    "\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Train\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  print()\n",
    "  print('Training...')\n",
    "  train(model_dir, data_dir, steps=Training_Steps)\n",
    "\n",
    "  log_event('trainMins', {\n",
    "      'event_category': str(Training_Steps),\n",
    "      'value': round((time.time() - tick) // 60),\n",
    "  })\n",
    "\n",
    "\n",
    "  # ------------------------------------------------------------------------------\n",
    "  # Export\n",
    "  # ------------------------------------------------------------------------------\n",
    "  tick = time.time()\n",
    "\n",
    "  print()\n",
    "  print('Exporting model...')\n",
    "  export_and_download(model_dir)\n",
    "\n",
    "  log_event('exportMins', {'value': round((time.time() - tick) // 60)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "  \"\"\"Create and display a FileChooser widget.\"\"\"\n",
    "  log_event('runStarted', {})\n",
    "  gpu_type = get_gpu_type()\n",
    "  print(f'Using a {gpu_type} GPU...')\n",
    "  log_event('gpuType', {'event_category': gpu_type})\n",
    "\n",
    "  print('Upload Audio Manually...')\n",
    "  run_training(drive_dir='./samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "gtag('event', 'runStarted', {});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a NVIDIA GeForce RTX 2070 GPU...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "gtag('event', 'gpuType', {\"event_category\": \"NVIDIA GeForce RTX 2070\"});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload Audio Manually...\n"
     ]
    },
    {
     "data": {
      "application/javascript": "gtag('event', 'runTrainingStarted', {});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing DDSP...\n",
      "This should take about 2 minutes...\n",
      "Copying audio to local directory for training...\n",
      "Copying ./samples/hls.mp3 to audio/hls.mp3\n",
      "Preparing new dataset from `audio/`\n",
      "\n",
      "Creating dataset...\n",
      "This usually takes around 2-3 minutes for each minute of audio\n",
      "(10 minutes of training audio -> 20-30 minutes)\n",
      "Running the following command:\n",
      "!ddsp_prepare_tfrecord --input_audio_filepatterns=\"audio/*\" --output_tfrecord_path=\"data//train.tfrecord\" --num_shards=10 --sample_rate=16000 --frame_rate=50 --example_secs=4.0 --hop_secs=1.0 --viterbi=True --center=True\n"
     ]
    },
    {
     "data": {
      "application/javascript": "gtag('event', 'datasetMins', {\"value\": 0});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training...\n",
      "data/train.tfrecord*\n",
      "TFRecordProvider.file_pattern='data/train.tfrecord*'\n",
      "2024-06-04 14:26:54.145890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "/usr/local/lib/python3.8/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "2024-06-04 14:26:57.084461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.086669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.086788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0604 14:26:57.086986 138721878755136 ddsp_run.py:179] Restore Dir: ./samples/ddsp-training-2024-06-04-1301\n",
      "I0604 14:26:57.087208 138721878755136 ddsp_run.py:180] Save Dir: ./samples/ddsp-training-2024-06-04-1301\n",
      "I0604 14:26:57.090278 138721878755136 ddsp_run.py:152] Operative config not found in ./samples/ddsp-training-2024-06-04-1301\n",
      "I0604 14:26:57.100883 138721878755136 ddsp_run.py:184] Operative Gin Config:\n",
      "import ddsp\n",
      "import ddsp.training as ddsp2\n",
      "\n",
      "# Macros:\n",
      "# ==============================================================================\n",
      "batch_size = 16\n",
      "evaluators = [@BasicEvaluator]\n",
      "frame_rate = 50\n",
      "frame_size = 1024\n",
      "learning_rate = 0.0003\n",
      "n_samples = 64320\n",
      "sample_rate = 16000\n",
      "\n",
      "# Parameters for processors.Add:\n",
      "# ==============================================================================\n",
      "processors.Add.name = 'add'\n",
      "\n",
      "# Parameters for Autoencoder:\n",
      "# ==============================================================================\n",
      "Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
      "Autoencoder.encoder = None\n",
      "Autoencoder.losses = [@losses.SpectralLoss()]\n",
      "Autoencoder.preprocessor = @preprocessing.OnlineF0PowerPreprocessor()\n",
      "Autoencoder.processor_group = @processors.ProcessorGroup()\n",
      "\n",
      "# Parameters for Crop:\n",
      "# ==============================================================================\n",
      "Crop.crop_location = 'back'\n",
      "Crop.frame_size = 320\n",
      "\n",
      "# Parameters for evaluate:\n",
      "# ==============================================================================\n",
      "evaluate.batch_size = 32\n",
      "evaluate.data_provider = @data.TFRecordProvider()\n",
      "evaluate.evaluator_classes = %evaluators\n",
      "evaluate.num_batches = 5\n",
      "\n",
      "# Parameters for FilteredNoise:\n",
      "# ==============================================================================\n",
      "FilteredNoise.n_samples = %n_samples\n",
      "FilteredNoise.name = 'filtered_noise'\n",
      "FilteredNoise.scale_fn = @core.exp_sigmoid\n",
      "FilteredNoise.window_size = 0\n",
      "\n",
      "# Parameters for FilteredNoiseReverb:\n",
      "# ==============================================================================\n",
      "FilteredNoiseReverb.n_filter_banks = 32\n",
      "FilteredNoiseReverb.n_frames = 500\n",
      "FilteredNoiseReverb.name = 'reverb'\n",
      "FilteredNoiseReverb.reverb_length = 24000\n",
      "FilteredNoiseReverb.trainable = True\n",
      "\n",
      "# Parameters for get_model:\n",
      "# ==============================================================================\n",
      "get_model.model = @models.Autoencoder()\n",
      "\n",
      "# Parameters for Harmonic:\n",
      "# ==============================================================================\n",
      "Harmonic.amp_resample_method = 'linear'\n",
      "Harmonic.n_samples = %n_samples\n",
      "Harmonic.name = 'harmonic'\n",
      "Harmonic.normalize_below_nyquist = True\n",
      "Harmonic.sample_rate = %sample_rate\n",
      "Harmonic.scale_fn = @core.exp_sigmoid\n",
      "\n",
      "# Parameters for OnlineF0PowerPreprocessor:\n",
      "# ==============================================================================\n",
      "OnlineF0PowerPreprocessor.compute_f0 = False\n",
      "OnlineF0PowerPreprocessor.compute_power = True\n",
      "OnlineF0PowerPreprocessor.crepe_saved_model_path = None\n",
      "OnlineF0PowerPreprocessor.frame_rate = %frame_rate\n",
      "OnlineF0PowerPreprocessor.frame_size = %frame_size\n",
      "OnlineF0PowerPreprocessor.padding = 'center'\n",
      "\n",
      "# Parameters for ProcessorGroup:\n",
      "# ==============================================================================\n",
      "ProcessorGroup.dag = \\\n",
      "    [(@synths.Harmonic(), ['amps', 'harmonic_distribution', 'f0_hz']),\n",
      "     (@synths.FilteredNoise(), ['noise_magnitudes']),\n",
      "     (@processors.Add(), ['filtered_noise/signal', 'harmonic/signal']),\n",
      "     (@effects.FilteredNoiseReverb(), ['add/signal']),\n",
      "     (@processors.Crop(), ['reverb/signal'])]\n",
      "\n",
      "# Parameters for RnnFcDecoder:\n",
      "# ==============================================================================\n",
      "RnnFcDecoder.ch = 256\n",
      "RnnFcDecoder.input_keys = ('pw_scaled', 'f0_scaled')\n",
      "RnnFcDecoder.layers_per_stack = 1\n",
      "RnnFcDecoder.output_splits = \\\n",
      "    (('amps', 1), ('harmonic_distribution', 60), ('noise_magnitudes', 65))\n",
      "RnnFcDecoder.rnn_channels = 512\n",
      "RnnFcDecoder.rnn_type = 'gru'\n",
      "\n",
      "# Parameters for sample:\n",
      "# ==============================================================================\n",
      "sample.batch_size = 16\n",
      "sample.ckpt_delay_secs = 300\n",
      "sample.data_provider = @data.TFRecordProvider()\n",
      "sample.evaluator_classes = %evaluators\n",
      "sample.num_batches = 1\n",
      "\n",
      "# Parameters for SpectralLoss:\n",
      "# ==============================================================================\n",
      "SpectralLoss.logmag_weight = 1.0\n",
      "SpectralLoss.loss_type = 'L1'\n",
      "SpectralLoss.mag_weight = 1.0\n",
      "\n",
      "# Parameters for TFRecordProvider:\n",
      "# ==============================================================================\n",
      "TFRecordProvider.centered = True\n",
      "TFRecordProvider.file_pattern = 'data/train.tfrecord*'\n",
      "TFRecordProvider.frame_rate = 50\n",
      "\n",
      "# Parameters for train:\n",
      "# ==============================================================================\n",
      "train.batch_size = %batch_size\n",
      "train.data_provider = @data.TFRecordProvider()\n",
      "train.num_steps = 30000\n",
      "train.steps_per_save = 300\n",
      "train.steps_per_summary = 300\n",
      "\n",
      "# Parameters for Trainer:\n",
      "# ==============================================================================\n",
      "Trainer.checkpoints_to_keep = 3\n",
      "Trainer.grad_clip_norm = 3.0\n",
      "Trainer.learning_rate = %learning_rate\n",
      "Trainer.lr_decay_rate = 0.98\n",
      "Trainer.lr_decay_steps = 10000\n",
      "\n",
      "I0604 14:26:57.101012 138721878755136 train_util.py:76] Defaulting to MirroredStrategy\n",
      "2024-06-04 14:26:57.101360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-04 14:26:57.101752: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.101910: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.102007: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.687944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.689620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.689730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:26:57.689821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3108 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0604 14:26:57.747757 138721878755136 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/ddsp_run\", line 8, in <module>\n",
      "    sys.exit(console_entry_point())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/ddsp_run.py\", line 227, in console_entry_point\n",
      "    app.run(main)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/ddsp_run.py\", line 197, in main\n",
      "    train_util.train(data_provider=gin.REQUIRED,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 1605, in gin_wrapper\n",
      "    utils.augment_exception_message_and_reraise(e, err_str)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gin/utils.py\", line 41, in augment_exception_message_and_reraise\n",
      "    raise proxy.with_traceback(exception.__traceback__) from None\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/gin/config.py\", line 1582, in gin_wrapper\n",
      "    return fn(*new_args, **new_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py\", line 242, in train\n",
      "    dataset = data_provider.get_batch(batch_size, shuffle=True, repeats=-1)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data.py\", line 74, in get_batch\n",
      "    dataset = self.get_dataset(shuffle)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data.py\", line 248, in get_dataset\n",
      "    filenames = tf.data.Dataset.list_files(self._file_pattern, shuffle=shuffle)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1471, in list_files\n",
      "    assert_not_empty = control_flow_ops.Assert(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 156, in Assert\n",
      "    raise errors.InvalidArgumentError(\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: data/train.tfrecord*'\n",
      "  In call to configurable 'train' (<function train at 0x7e2a09e5a790>)\n"
     ]
    },
    {
     "data": {
      "application/javascript": "gtag('event', 'trainMins', {\"event_category\": \"30000\", \"value\": 0});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting model...\n",
      "2024-06-04 14:26:58.945484: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "/usr/local/lib/python3.8/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "2024-06-04 14:27:02.588481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:27:02.592408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:27:02.592538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py\", line 164, in get_latest_operative_config\n",
      "    return get_latest_file(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py\", line 105, in get_latest_file\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: No files found matching the pattern './samples/ddsp-training-2024-06-04-1301/operative_config-*.gin'.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/ddsp_export\", line 8, in <module>\n",
      "    sys.exit(console_entry_point())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/ddsp_export.py\", line 368, in console_entry_point\n",
      "    app.run(main)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/ddsp_export.py\", line 337, in main\n",
      "    export_impulse_response(model_path, save_dir, FLAGS.reverb_sample_rate)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/ddsp_export.py\", line 276, in export_impulse_response\n",
      "    ddsp.training.inference.parse_operative_config(model_path)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/inference.py\", line 41, in parse_operative_config\n",
      "    operative_config = train_util.get_latest_operative_config(ckpt_dir)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py\", line 167, in get_latest_operative_config\n",
      "    return get_latest_file(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/train_util.py\", line 105, in get_latest_file\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: No files found matching the pattern './samples/operative_config-*.gin'.\n",
      "Export complete! Zipping ./samples/ddsp-training-2024-06-04-1301/My_Instrument to ./samples/ddsp-training-2024-06-04-1301/My_Instrument.zip\n",
      "Zipping Complete! Downloading... My_Instrument.zip\n",
      "You can also find your model at ./samples/ddsp-training-2024-06-04-1301/My_Instrument\n"
     ]
    },
    {
     "data": {
      "application/javascript": "gtag('event', 'exportMins', {\"value\": 0});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-downloader in /usr/local/lib/python3.8/dist-packages (0.3.0)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.8/dist-packages (from ffmpeg-downloader) (4.2.2)\n",
      "Requirement already satisfied: tqdm>=4.40.0 in /usr/local/lib/python3.8/dist-packages (from ffmpeg-downloader) (4.66.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ffmpeg-downloader) (2.32.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ffmpeg-downloader) (20.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->ffmpeg-downloader) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->ffmpeg-downloader) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->ffmpeg-downloader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->ffmpeg-downloader) (2.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->ffmpeg-downloader) (2.4.7)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-downloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg==7.0 in /root/.local/share/ffmpeg-downloader/ffmpeg\n"
     ]
    }
   ],
   "source": [
    "!ffdl install --add-path -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 14:27:57.019437: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:561: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "/usr/local/lib/python3.8/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "2024-06-04 14:28:00.075152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:28:00.077395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-04 14:28:00.077536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I0604 14:28:00.290451 130182227011392 statecache.py:234] Creating state cache with size 104857600\n",
      "I0604 14:28:00.332656 130182227011392 prepare_tfrecord_lib.py:58] Loading 'audio/hls.mp3'.\n",
      "/usr/local/lib/python3.8/dist-packages/pydub/utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n",
      "E0604 14:28:00.416296 130182227011392 bundle_processor.py:237] FileNotFoundError: [Errno 2] No such file or directory: 'ffprobe' [while running 'Map(_load_audio)']\n",
      "Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 861, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 999, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/transforms/core.py\", line 1967, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 60, in _load_audio\n",
      "    audio = _load_audio_as_array(audio_path, sample_rate)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 42, in _load_audio_as_array\n",
      "    audio_segment = (pydub.AudioSegment.from_file(f).set_channels(1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/audio_segment.py\", line 728, in from_file\n",
      "    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/utils.py\", line 274, in mediainfo_json\n",
      "    res = Popen(command, stdin=stdin_parameter, stdout=PIPE, stderr=PIPE)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1704, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'ffprobe'\n",
      "Traceback (most recent call last):\n",
      "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 861, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 999, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/transforms/core.py\", line 1967, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 60, in _load_audio\n",
      "    audio = _load_audio_as_array(audio_path, sample_rate)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 42, in _load_audio_as_array\n",
      "    audio_segment = (pydub.AudioSegment.from_file(f).set_channels(1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/audio_segment.py\", line 728, in from_file\n",
      "    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/utils.py\", line 274, in mediainfo_json\n",
      "    res = Popen(command, stdin=stdin_parameter, stdout=PIPE, stderr=PIPE)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1704, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'ffprobe'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/ddsp_prepare_tfrecord\", line 8, in <module>\n",
      "    sys.exit(console_entry_point())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/ddsp_prepare_tfrecord.py\", line 111, in console_entry_point\n",
      "    app.run(main)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/ddsp_prepare_tfrecord.py\", line 106, in main\n",
      "    run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/ddsp_prepare_tfrecord.py\", line 89, in run\n",
      "    prepare_tfrecord(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 272, in prepare_tfrecord\n",
      "    postprocess_pipeline(examples, output_tfrecord_path)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/pipeline.py\", line 613, in __exit__\n",
      "    self.result = self.run()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/pipeline.py\", line 587, in run\n",
      "    return self.runner.run_pipeline(self, self._options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/direct/direct_runner.py\", line 128, in run_pipeline\n",
      "    return runner.run_pipeline(pipeline, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 204, in run_pipeline\n",
      "    self._latest_run_result = self.run_via_runner_api(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 228, in run_via_runner_api\n",
      "    return self.run_stages(stage_context, stages)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 483, in run_stages\n",
      "    bundle_results = self._execute_bundle(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 811, in _execute_bundle\n",
      "    self._run_bundle(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 1048, in _run_bundle\n",
      "    result, splits = bundle_manager.process_bundle(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/fn_runner.py\", line 1384, in process_bundle\n",
      "    result_future = self._worker_handler.control_conn.push(process_bundle_req)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/portability/fn_api_runner/worker_handlers.py\", line 384, in push\n",
      "    response = self.worker.do_instruction(request)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/worker/sdk_worker.py\", line 656, in do_instruction\n",
      "    return getattr(self, request_type)(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/worker/sdk_worker.py\", line 694, in process_bundle\n",
      "    bundle_processor.process_bundle(instruction_id))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/worker/bundle_processor.py\", line 1113, in process_bundle\n",
      "    input_op_by_transform_id[element.transform_id].process_encoded(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/runners/worker/bundle_processor.py\", line 237, in process_encoded\n",
      "    self.output(decoded_value)\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 569, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 571, in apache_beam.runners.worker.operations.Operation.output\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 262, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 265, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 952, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 953, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1437, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1526, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 639, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 1621, in apache_beam.runners.common._OutputHandler.handle_process_outputs\n",
      "  File \"apache_beam/runners/common.py\", line 1734, in apache_beam.runners.common._OutputHandler._write_value_to_tag\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 265, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 952, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 953, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1437, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1526, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 639, in apache_beam.runners.common.SimpleInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 1621, in apache_beam.runners.common._OutputHandler.handle_process_outputs\n",
      "  File \"apache_beam/runners/common.py\", line 1734, in apache_beam.runners.common._OutputHandler._write_value_to_tag\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 265, in apache_beam.runners.worker.operations.SingletonElementConsumerSet.receive\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 952, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/worker/operations.py\", line 953, in apache_beam.runners.worker.operations.DoOperation.process\n",
      "  File \"apache_beam/runners/common.py\", line 1437, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 1547, in apache_beam.runners.common.DoFnRunner._reraise_augmented\n",
      "  File \"apache_beam/runners/common.py\", line 1435, in apache_beam.runners.common.DoFnRunner.process\n",
      "  File \"apache_beam/runners/common.py\", line 861, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n",
      "  File \"apache_beam/runners/common.py\", line 999, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/apache_beam/transforms/core.py\", line 1967, in <lambda>\n",
      "    wrapper = lambda x, *args, **kwargs: [fn(x, *args, **kwargs)]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 60, in _load_audio\n",
      "    audio = _load_audio_as_array(audio_path, sample_rate)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/ddsp/training/data_preparation/prepare_tfrecord_lib.py\", line 42, in _load_audio_as_array\n",
      "    audio_segment = (pydub.AudioSegment.from_file(f).set_channels(1))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/audio_segment.py\", line 728, in from_file\n",
      "    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pydub/utils.py\", line 274, in mediainfo_json\n",
      "    res = Popen(command, stdin=stdin_parameter, stdout=PIPE, stderr=PIPE)\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 858, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/lib/python3.8/subprocess.py\", line 1704, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "RuntimeError: FileNotFoundError: [Errno 2] No such file or directory: 'ffprobe' [while running 'Map(_load_audio)']\n"
     ]
    }
   ],
   "source": [
    "!ddsp_prepare_tfrecord --input_audio_filepatterns=\"audio/*\" --output_tfrecord_path=\"data//train.tfrecord\" --num_shards=10 --sample_rate=16000 --frame_rate=50 --example_secs=4.0 --hop_secs=1.0 --viterbi=True --center=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
